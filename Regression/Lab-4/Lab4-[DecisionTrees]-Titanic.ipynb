{"cells":[{"cell_type":"markdown","metadata":{"id":"NvtQ7-AGTcJH"},"source":["# Predict survival on the Titanic\n","In this Lab, we ask you to apply the tools of machine learning to predict which passengers survived the tragedy"]},{"cell_type":"markdown","metadata":{"id":"KZ58PLGeTcJO"},"source":["### Dataset\n","The dataset contains 891 observations of 12 variables:\n","* **PassengerId**: Unique ID for each passenger\n","* **Survived**: Survival (0 = No; 1 = Yes)\n","* **Pclass**: Passenger Class (1 = 1st; 2 = 2nd; 3 = 3rd)\n","* **Name**: Name\n","* **Sex**: Sex\n","* **Age**: Age\n","* **Sibsp**: Number of Siblings/Spouses Aboard\n","* **Parch**: Number of Parents/Children Aboard\n","* **Ticket**: Ticket Number\n","* **Fare**: Passenger Fare\n","* **Cabin**: Cabin\n","* **Embarked** Port of Embarkation (C = Cherbourg; Q = Queenstown; S = Southampton)"]},{"cell_type":"code","source":["import os\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JKrKm07xUIJz","executionInfo":{"status":"ok","timestamp":1642964511407,"user_tz":-60,"elapsed":23053,"user":{"displayName":"khadija slimani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1ndWppI5BJYSS_qkdZx68rRhC14tGvQ3nHe1s=s64","userId":"08046443806445099499"}},"outputId":"a2fbc8af-7fe4-4349-ea27-35f0b3b7e90c"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["cd drive/MyDrive/Machine\\ Learning\\ Labs/Week4"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dJyB8w50aSra","executionInfo":{"status":"ok","timestamp":1642966122438,"user_tz":-60,"elapsed":353,"user":{"displayName":"khadija slimani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1ndWppI5BJYSS_qkdZx68rRhC14tGvQ3nHe1s=s64","userId":"08046443806445099499"}},"outputId":"6021d92f-5c9a-42de-d9e9-b36f1e43084c"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Machine Learning Labs/Week4\n"]}]},{"cell_type":"code","execution_count":5,"metadata":{"id":"vSYIOMD7TcJP","executionInfo":{"status":"ok","timestamp":1642966131012,"user_tz":-60,"elapsed":346,"user":{"displayName":"khadija slimani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1ndWppI5BJYSS_qkdZx68rRhC14tGvQ3nHe1s=s64","userId":"08046443806445099499"}}},"outputs":[],"source":["# imports\n","import warnings\n","warnings.filterwarnings('ignore')\n","import pandas as pd\n","import numpy as np"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vv_oA10PTcJR","executionInfo":{"status":"ok","timestamp":1642966136189,"user_tz":-60,"elapsed":1665,"user":{"displayName":"khadija slimani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1ndWppI5BJYSS_qkdZx68rRhC14tGvQ3nHe1s=s64","userId":"08046443806445099499"}},"outputId":"ded3bbf3-f780-4118-aafc-f50052f97650"},"outputs":[{"output_type":"stream","name":"stdout","text":["survival rate = 0.3838383838383838\n"]}],"source":["titanic = pd.read_csv(\"titanic.csv\" )\n","titanic.drop('Cabin', axis=1, inplace=True) # Drop this column because it contains a lot of Nan values\n","titanic[\"Age\"].fillna(titanic[\"Age\"].median(),inplace=True)\n","titanic[\"Embarked\"].fillna(\"S\", inplace = True)\n","print ('survival rate =', titanic.Survived.mean())"]},{"cell_type":"markdown","metadata":{"id":"Ye28nQ0fTcJS"},"source":["## Model training"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"3fSZeYosTcJT","executionInfo":{"status":"ok","timestamp":1642966175753,"user_tz":-60,"elapsed":343,"user":{"displayName":"khadija slimani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1ndWppI5BJYSS_qkdZx68rRhC14tGvQ3nHe1s=s64","userId":"08046443806445099499"}},"outputId":"09579277-5e5f-4ad3-d146-2ee89d1cbfce"},"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-0928f0fc-8107-4a72-8ccc-93a14fb2bfac\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PassengerId</th>\n","      <th>Survived</th>\n","      <th>Pclass</th>\n","      <th>Name</th>\n","      <th>Sex</th>\n","      <th>Age</th>\n","      <th>SibSp</th>\n","      <th>Parch</th>\n","      <th>Ticket</th>\n","      <th>Fare</th>\n","      <th>Embarked</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Braund, Mr. Owen Harris</td>\n","      <td>1</td>\n","      <td>22.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>A/5 21171</td>\n","      <td>7.2500</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n","      <td>0</td>\n","      <td>38.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>PC 17599</td>\n","      <td>71.2833</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>Heikkinen, Miss. Laina</td>\n","      <td>0</td>\n","      <td>26.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>STON/O2. 3101282</td>\n","      <td>7.9250</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n","      <td>0</td>\n","      <td>35.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>113803</td>\n","      <td>53.1000</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Allen, Mr. William Henry</td>\n","      <td>1</td>\n","      <td>35.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>373450</td>\n","      <td>8.0500</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0928f0fc-8107-4a72-8ccc-93a14fb2bfac')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-0928f0fc-8107-4a72-8ccc-93a14fb2bfac button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-0928f0fc-8107-4a72-8ccc-93a14fb2bfac');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["   PassengerId  Survived  Pclass  ...            Ticket     Fare  Embarked\n","0            1         0       3  ...         A/5 21171   7.2500         2\n","1            2         1       1  ...          PC 17599  71.2833         0\n","2            3         1       3  ...  STON/O2. 3101282   7.9250         2\n","3            4         1       1  ...            113803  53.1000         2\n","4            5         0       3  ...            373450   8.0500         2\n","\n","[5 rows x 11 columns]"]},"metadata":{},"execution_count":7}],"source":["# Some of the columns don't have predictive power, so let's specify which ones are included for prediction\n","predictors = [\"Pclass\", \"Sex\", \"Age\", 'SibSp' ,'Parch', \"Fare\", \"Embarked\"]  \n","# We need now to convert text columns in predictors to numerical ones\n","for col in predictors: # Loop through all columns in predictors\n","    if titanic[col].dtype == 'object':  # check if column's type is object (text)\n","        titanic[col] = pd.Categorical(titanic[col]).codes  # convert text to numerical\n","\n","titanic.head()"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WVI1Aip6TcJU","executionInfo":{"status":"ok","timestamp":1642966343142,"user_tz":-60,"elapsed":786,"user":{"displayName":"khadija slimani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1ndWppI5BJYSS_qkdZx68rRhC14tGvQ3nHe1s=s64","userId":"08046443806445099499"}},"outputId":"6b747316-dcea-4f40-e5d4-19c31d7e87ae"},"outputs":[{"output_type":"stream","name":"stdout","text":["train accuracy = 0.8073836276083467\n","cross validation accuracy = 0.7957428214731586\n"]}],"source":["# Split the data into a training set and a testing set\n","from sklearn.model_selection import train_test_split \n","X_train, X_test, y_train, y_test = train_test_split(titanic[predictors], titanic['Survived'], test_size=0.3, random_state=1)\n","\n","from sklearn.linear_model import LogisticRegression\n","clf = LogisticRegression(random_state=1)\n","clf.fit(X_train, y_train)\n","train_score = clf.score(X_train, y_train)\n","print ('train accuracy =', clf.score(X_train, y_train))\n","\n","from sklearn.model_selection import cross_val_score\n","scores = cross_val_score(clf, titanic[predictors], titanic[\"Survived\"], scoring='accuracy', cv=10)\n","print('cross validation accuracy =', scores.mean())"]},{"cell_type":"markdown","metadata":{"collapsed":true,"id":"dUHOUJYPTcJV"},"source":[" # Decision Trees"]},{"cell_type":"markdown","metadata":{"id":"FO9Bqr0bTcJV"},"source":["Let's start with one single tree"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RAoIhHvaTcJW","outputId":"016d1e35-104d-4758-e9f3-ec7fe840f062"},"outputs":[{"ename":"SyntaxError","evalue":"unexpected EOF while parsing (<ipython-input-7-465026c406ec>, line 6)","output_type":"error","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-465026c406ec>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    print ('test accuracy =', # your code here)\u001b[0m\n\u001b[0m                                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"]}],"source":["# import from: http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier\n","# your code here\n","clf_dt = DecisionTreeClassifier(random_state=1)\n","# your code here\n","print ('train accuracy =', # your code here)\n","print ('test accuracy =', # your code here)"]},{"cell_type":"markdown","metadata":{"id":"BaMhzYP6TcJX"},"source":["Predictions are obtained in the same way of Logistic Regression"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"6myppkpzTcJX"},"outputs":[],"source":["y_pred = # your code here\n","print (y_pred)"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"G1F87kSWTcJY"},"outputs":[],"source":["y_prob = # your code here\n","print (y_prob)"]},{"cell_type":"markdown","metadata":{"id":"HVJc7_t5TcJY"},"source":["Let's play around with some of the decision tree's parameters"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"LidWWO_5TcJZ"},"outputs":[],"source":["# check the sklearn documentation and change the folowing parametrs: max_depth, min_samples_split, min_samples_leaf \n","clf_dt = DecisionTreeClassifier(random_state=1, # your code here)\n","# your code here\n","print ('train accuracy =', # your code here)\n","\n","# Cross validation\n","scores_dt = # your code here\n","print('cross validation accuracy =', # your code here)"]},{"cell_type":"markdown","metadata":{"id":"qUCeJJDqTcJZ"},"source":["### Plot the decision tree\n","Set the max_depth parameter in the previous classifier to 3 and leave all the other ones to default values."]},{"cell_type":"code","execution_count":11,"metadata":{"collapsed":true,"colab":{"base_uri":"https://localhost:8080/","height":226},"id":"eF0I14EnTcJZ","executionInfo":{"status":"error","timestamp":1642967339375,"user_tz":-60,"elapsed":383,"user":{"displayName":"khadija slimani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1ndWppI5BJYSS_qkdZx68rRhC14tGvQ3nHe1s=s64","userId":"08046443806445099499"}},"outputId":"547b9233-c245-493d-f298-b46bc1dfe9a5"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-869e2ddc0038>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport_graphviz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf_dt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'tree.dot'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# As a reminder, these are the predicting features in order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredictors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'clf_dt' is not defined"]}],"source":["from sklearn import tree\n","tree.export_graphviz(clf_dt, out_file='tree.dot')\n","# As a reminder, these are the predicting features in order\n","print (dict(zip(range(len(predictors)),predictors)))"]},{"cell_type":"markdown","metadata":{"id":"KMW9LgwiTcJZ"},"source":["The image should look like the following"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"TigcBlbYTcJa"},"outputs":[],"source":["from IPython.display import Image\n","Image(\"DT.png\")"]},{"cell_type":"markdown","metadata":{"id":"ZQc5hNHvTcJa"},"source":["Predict the survival of a female, Pclass 1 or 2, above age 2.5"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"WO-lf5nmTcJa"},"outputs":[],"source":["passenger1=np.array([# your code here]).reshape(1, -1)\n","print ('proba =', # your code here)\n","print ('class =', # your code here)"]},{"cell_type":"markdown","metadata":{"id":"lIwhg1g_TcJa"},"source":["Predict the survival of a male, above age 11.5, Pclass 2 or 3"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"O6qxxP_3TcJb"},"outputs":[],"source":["passenger2=np.array([# your code here]).reshape(1, -1)\n","print ('proba =', # your code here)\n","print ('class =', # your code here)"]},{"cell_type":"markdown","metadata":{"id":"J9ZjCb9cTcJb"},"source":["By looking at this decision tree, you can get a sense the relative importance between features. let's see which are the most important ones using the attribute: **feature\\_importances_**"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"7YV2L9y_TcJb"},"outputs":[],"source":["feat_imp = pd.DataFrame(clf_dt.feature_importances_, predictors, columns=['Importance'])\n","feat_imp.sort_values('Importance', ascending=False)"]},{"cell_type":"markdown","metadata":{"id":"iI60dASRTcJb"},"source":["As expected, **Parch** and **Fare** are the least important ones because they were not used for splitting, while **Sex** is the most important one since it was used first for splitting. "]},{"cell_type":"markdown","metadata":{"id":"Cx_8UNxITcJb"},"source":["# Random Forest\n","A   [Random Forest](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier from sklearn.ensemble import RandomForestClassifier) is an ensemble of [decision trees](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier)"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"GMngEhgoTcJc"},"outputs":[],"source":["# import from: http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier\n","# your code here\n","clf_rf = RandomForestClassifier(random_state=1)  # by default, 10 trees are used\n","# your code here\n","print ('train accuracy =', # your code here)\n","\n","# Cross validation\n","scores_rf = # your code here\n","print('cross validation accuracy =', # your code here)"]},{"cell_type":"markdown","metadata":{"id":"r0DMc-SATcJc"},"source":["In the same way, you can print the feature importance of all the trees"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"AITkrvNdTcJc"},"outputs":[],"source":["# your code here"]},{"cell_type":"markdown","metadata":{"id":"FkgWyB5oTcJc"},"source":["Random forest, like decision trees have a lot of parameters to tune. Usually, performance does not change linearly with parameters. Let's take as an example, the accuracy as a function of number of trees (**n_estimators**)"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"scrolled":true,"id":"v_4flYtCTcJd"},"outputs":[],"source":["%matplotlib inline\n","import matplotlib.pyplot as plt\n","\n","trees=range(50)\n","accuracy=np.zeros(50)\n","for idx in range(len(trees)):\n","    clf_rf=RandomForestClassifier(random_state=1, n_estimators=idx + 1)\n","    clf_rf.fit(X_train,y_train)\n","    accuracy[idx]=clf_rf.score(X_test, y_test)  \n","\n","plt.plot(trees, accuracy)\n","plt.ylabel('accuracy')\n","plt.xlabel('Number of Trees')"]},{"cell_type":"markdown","metadata":{"id":"BeJ0N7k1TcJd"},"source":["In the following, try to tune manually the following parameters: **min_samples_leaf, min_samples_split, max_depth, n_estimators** in order to increase cross validation accuracy."]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"XUvA1sZUTcJd"},"outputs":[],"source":["clf_rf = RandomForestClassifier(random_state=1, # your code here)\n","clf_rf.fit(X_train, y_train)\n","print ('train accuracy =', clf_rf.score(X_train, y_train))\n","\n","# Cross validation\n","scores_rf = cross_validation.cross_val_score(clf_rf, titanic[predictors], titanic[\"Survived\"], scoring='accuracy', cv=5)\n","print('cross validation accuracy =', scores_rf.mean())"]},{"cell_type":"markdown","metadata":{"id":"F41IStn3TcJd"},"source":["This might be a difficult job to do manually. In other way is to search automatically the best combination of different ranges for these parameters. This is done using **Grid Search**"]},{"cell_type":"markdown","metadata":{"id":"LfhP3X06TcJe"},"source":["# Grid Search"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"_lgu9l0sTcJe"},"outputs":[],"source":["# Documentation: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV\n","# your code here\n","params = {'min_samples_leaf':list(range(1,5)),'min_samples_split':list(range(2,10,2)),\n","          'n_estimators':list(range(10,50,10))}\n","clf_rf2=RandomForestClassifier(random_state=1)\n","clf_gs=GridSearchCV(clf_rf2, params, scoring = 'accuracy',cv=5)\n","clf_gs.fit(titanic[predictors], titanic[\"Survived\"])"]},{"cell_type":"markdown","metadata":{"id":"hbP8ZmPRTcJe"},"source":["Print the best score"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"I0FpYW71TcJe"},"outputs":[],"source":["# your code here"]},{"cell_type":"markdown","metadata":{"id":"mLvOdM5ZTcJe"},"source":["Print the best parameters"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"1Ps3_hrETcJf"},"outputs":[],"source":["# your code here"]},{"cell_type":"markdown","metadata":{"id":"gtZigzEQTcJf"},"source":["Let's use these best parameters and check whether they achieve really the above cv accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"1MIQzMGTTcJf"},"outputs":[],"source":["clf_rf3 = RandomForestClassifier(random_state=1, # your code here) \n","clf_rf3.fit(X_train, y_train)\n","print ('train accuracy =', clf_rf3.score(X_train, y_train))\n","\n","scores_rf3 = cross_validation.cross_val_score(clf_rf3, titanic[predictors], titanic[\"Survived\"], scoring='accuracy', cv=5)\n","print('cross validation accuracy =',scores_rf3.mean())"]},{"cell_type":"markdown","metadata":{"collapsed":true,"id":"k9SYsvwsTcJf"},"source":["As you can see, grid search allows you to find the best model parameters to improve your accuracy. Now, we can see the most important features of this last classifier"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"zxb-ZoNMTcJf"},"outputs":[],"source":["feat_imp = pd.DataFrame(clf_rf3.feature_importances_, predictors, columns=['Importance'])\n","feat_imp.sort_values('Importance', ascending=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"jw9VJuhHTcJf"},"outputs":[],"source":[""]}],"metadata":{"anaconda-cloud":{},"kernelspec":{"display_name":"ml_week2","language":"python","name":"ml_week2"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"},"colab":{"name":"Lab3-[DecisionTrees]-Titanic.ipynb","provenance":[]}},"nbformat":4,"nbformat_minor":0}